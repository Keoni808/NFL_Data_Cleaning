{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ciN_CS4bOcpV",
        "rTlTgrlpO_q1",
        "ELSW1R82_TqT",
        "uau4ner4_fug",
        "9L_L6vxtmnLQ",
        "K5cZryPjsnxd",
        "CZpJpikZCx--",
        "TrudwcGMsfXh",
        "lXOsRYYuiXxf",
        "Kty3o5BakJHM",
        "rnZ_khFBkMkX"
      ],
      "authorship_tag": "ABX9TyNSeKPOy6ASPZOfRCZFWiEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeoniM/NFL_Data_Cleaning/blob/main/NFL_Plays_Week1_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PURPOSE:\n",
        "- Correctly clean a week sample size of plays\n",
        "  - Season 2023 -> Week 1\n",
        "\n",
        "CONCERNS FOR LATER:\n",
        "- Players with the same name\n",
        "  - The current goal is to use the fewest possible indicators or features to distinguish between players with the same name.\n",
        "    - Maybe there is a more simple way?\n",
        "- Trick plays\n",
        "  - latterals  \n",
        "- Cleaning check\n",
        "  - I need to figure out how to create some type of check to make sure that these plays are being cleaned correctly.\n",
        "\n",
        "LATER IDEAS:\n",
        "- One size fits all 'Fumble' helper method. <---\n",
        "- Create a category \"ForceFumbleBy\" <---\n",
        "- Use 'fuzzywuzzy' to group like play outcomes to parse different plays\n",
        "- Map team name with their abbreviations ( e.g. \"Cowboys\" <-> \"DAL\" )\n",
        "  - Maybe with larger datasets with multiple weeks, I can map team names with team abbrevations that match up the most.\n",
        "\n",
        "DEFENSE GOALS:\n",
        "- Grab/Decifer/categorize 'Passes Defended'"
      ],
      "metadata": {
        "id": "bDIp3ojKOdg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOUNTING AND IMPORTS"
      ],
      "metadata": {
        "id": "ciN_CS4bOcpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3J98keONRD",
        "outputId": "f122a089-3c15-4b0b-f7ae-6676216e2c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to access personal google cloud services\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gLupTRXO5gw",
        "outputId": "5d418426-b2f0-4ddb-e79d-4b6da8e21b25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Grab data from database\n",
        "from google.cloud import bigquery"
      ],
      "metadata": {
        "id": "1YadW6p7O7Lf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # debugger (maybe use in the future)\n",
        "# %pdb on"
      ],
      "metadata": {
        "id": "jKpGDloBiQN8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA (BigQuery queries)"
      ],
      "metadata": {
        "id": "rTlTgrlpO_q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Client connect to bigquery project\n",
        "client = bigquery.Client('nfl-data-430702')"
      ],
      "metadata": {
        "id": "W05L1TH6PAcb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Season 2023 Week 1"
      ],
      "metadata": {
        "id": "HPdKuDJJPIUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grabbing all plays from 2023 Week 1 NFL Sesason\n",
        "week1_2023_plays_query = \"\"\"\n",
        "                         SELECT *\n",
        "                         FROM `nfl-data-430702.NFL_Scores.NFL-Plays-Week1_2023`\n",
        "                         \"\"\"\n",
        "\n",
        "# Running psuedo query, and returns the amount of bytes it will take to run query\n",
        "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
        "dry_run_query = client.query(week1_2023_plays_query, job_config=dry_run_config)\n",
        "print(\"This query will process {} bytes.\".format(dry_run_query.total_bytes_processed))\n",
        "\n",
        "# Running query (Being mindful of the amount of data being grabbed)\n",
        "# Will grab a maximum of a Gigabyte\n",
        "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\n",
        "safe_config_query = client.query(week1_2023_plays_query, job_config=safe_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnOg_zdhPLHi",
        "outputId": "610fc1c6-0de3-4463-c3c5-467b2cbd85e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This query will process 570194 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting data attained from query into a dataframe\n",
        "week1_2023_plays = safe_config_query.to_dataframe()"
      ],
      "metadata": {
        "id": "27xLLVO6PfSJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "week1_2023_plays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pJP-0GxhPhI_",
        "outputId": "2396a500-355e-4908-8c90-b5bafb4ef6f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Season    Week  Day   Date AwayTeam HomeTeam      Quarter  DriveNumber  \\\n",
              "0    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "1    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "2    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "3    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "4    2023  Week 1  MON  09/11    Bills     Jets  1ST QUARTER            1   \n",
              "\n",
              "  TeamWithPossession  IsScoringDrive  PlayNumberInDrive  IsScoringPlay  \\\n",
              "0                BUF               0                  1              0   \n",
              "1                BUF               0                  2              0   \n",
              "2                BUF               0                  3              0   \n",
              "3                BUF               0                  4              0   \n",
              "4                BUF               0                  5              0   \n",
              "\n",
              "   PlayOutcome                                    PlayDescription  \\\n",
              "0      Kickoff  G.Zuerlein kicks 65 yards from NYJ 35 to end z...   \n",
              "1  7 Yard Pass  (15:00) (Shotgun) J.Allen pass short right to ...   \n",
              "2  5 Yard Pass  (14:34) (No Huddle, Shotgun) J.Allen pass shor...   \n",
              "3   3 Yard Run  (14:01) J.Cook up the middle to BUF 40 for 3 y...   \n",
              "4   2 Yard Run  (13:24) (Shotgun) J.Cook up the middle to BUF ...   \n",
              "\n",
              "             PlayStart  \n",
              "0  Kickoff from NYJ 35  \n",
              "1   1st & 10 at BUF 25  \n",
              "2    2nd & 3 at BUF 32  \n",
              "3   1st & 10 at BUF 37  \n",
              "4    2nd & 7 at BUF 40  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a11637b-7a58-4f7f-b68d-67ef8287133f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Week</th>\n",
              "      <th>Day</th>\n",
              "      <th>Date</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>DriveNumber</th>\n",
              "      <th>TeamWithPossession</th>\n",
              "      <th>IsScoringDrive</th>\n",
              "      <th>PlayNumberInDrive</th>\n",
              "      <th>IsScoringPlay</th>\n",
              "      <th>PlayOutcome</th>\n",
              "      <th>PlayDescription</th>\n",
              "      <th>PlayStart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Kickoff</td>\n",
              "      <td>G.Zuerlein kicks 65 yards from NYJ 35 to end z...</td>\n",
              "      <td>Kickoff from NYJ 35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7 Yard Pass</td>\n",
              "      <td>(15:00) (Shotgun) J.Allen pass short right to ...</td>\n",
              "      <td>1st &amp; 10 at BUF 25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5 Yard Pass</td>\n",
              "      <td>(14:34) (No Huddle, Shotgun) J.Allen pass shor...</td>\n",
              "      <td>2nd &amp; 3 at BUF 32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 Yard Run</td>\n",
              "      <td>(14:01) J.Cook up the middle to BUF 40 for 3 y...</td>\n",
              "      <td>1st &amp; 10 at BUF 37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>MON</td>\n",
              "      <td>09/11</td>\n",
              "      <td>Bills</td>\n",
              "      <td>Jets</td>\n",
              "      <td>1ST QUARTER</td>\n",
              "      <td>1</td>\n",
              "      <td>BUF</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2 Yard Run</td>\n",
              "      <td>(13:24) (Shotgun) J.Cook up the middle to BUF ...</td>\n",
              "      <td>2nd &amp; 7 at BUF 40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a11637b-7a58-4f7f-b68d-67ef8287133f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a11637b-7a58-4f7f-b68d-67ef8287133f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a11637b-7a58-4f7f-b68d-67ef8287133f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45bae2b2-4313-492d-91f1-b735b5e6ade5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45bae2b2-4313-492d-91f1-b735b5e6ade5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45bae2b2-4313-492d-91f1-b735b5e6ade5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "week1_2023_plays",
              "summary": "{\n  \"name\": \"week1_2023_plays\",\n  \"rows\": 2600,\n  \"fields\": [\n    {\n      \"column\": \"Season\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Week 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"09/11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Bills\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Jets\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2ND QUARTER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DriveNumber\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TeamWithPossession\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"PIT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayNumberInDrive\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsScoringPlay\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayOutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 170,\n        \"samples\": [\n          \"Touchdown Buccaneers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayDescription\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2487,\n        \"samples\": [\n          \"(:54) (Shotgun) K.Cousins pass deep middle to J.Jefferson to TB 22 for 42 yards (A.Winfield).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PlayStart\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2119,\n        \"samples\": [\n          \"3rd & 16 at LA 18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Noting the original size of the raw uncleaned dataframe of data\n",
        "# - (rows, columns)\n",
        "week1_2023_plays.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oShT8MvlRQdR",
        "outputId": "c2573a42-ec99-40e1-fe9b-614e2d5e76f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2600, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CATEGORIZE PLAYS\n",
        "- The goal here is to parse out the different values for 'PlayOutcome'\n",
        "  - This is where I will separate different types of plays\n",
        "    - ( pass / run / kickoff / etc. )"
      ],
      "metadata": {
        "id": "9JD1VzJWRWn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe try to fuzzywuzzy this in the future?\n",
        "\n",
        "# All play outcomes from the game\n",
        "# - From here we can categorize and clean plays accordingly\n",
        "week1_2023_plays['PlayOutcome'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0WcGgv1RXl0",
        "outputId": "ba6ed4f3-8004-4235-c132-ba32da552391"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Kickoff', '7 Yard Pass', '5 Yard Pass', '3 Yard Run',\n",
              "       '2 Yard Run', 'Pass Incomplete', 'Punt', '-5 Yard Penalty',\n",
              "       '5 Yard Run', '1 Yard Pass', '14 Yard Run', '3 Yard Pass',\n",
              "       '8 Yard Run', '6 Yard Pass', '15 Yard Pass', '-9 Yard Sack',\n",
              "       '4 Yard Pass', '13 Yard Pass', 'Field Goal', '-2 Yard Sack',\n",
              "       'Interception', '-5 Yard Run', '18 Yard Pass', '8 Yard Pass',\n",
              "       '6 Yard Run', '12 Yard Run', '-1 Yard Run', '26 Yard Pass',\n",
              "       'Touchdown Bills', 'Extra Point Good', '13 Yard Run',\n",
              "       '-3 Yard Sack', '7 Yard Run', '9 Yard Pass', '4 Yard Run',\n",
              "       'Fumble', '-10 Yard Penalty', '10 Yard Pass', '26 Yard Run',\n",
              "       '5 Yard Penalty', '-10 Yard Sack', '22 Yard Pass', '-4 Yard Run',\n",
              "       '-12 Yard Sack', '83 Yard Run', '1 Yard Run', '2 Yard Pass',\n",
              "       '10 Yard Run', 'Run for No Gain', '12 Yard Pass', '20 Yard Pass',\n",
              "       '9 Yard Run', '-2 Yard Pass', 'Sack', '24 Yard Pass',\n",
              "       '14 Yard Pass', 'Touchdown Jets', '-3 Yard Run', '-2 Yard Run',\n",
              "       'Touchdown Packers', '16 Yard Pass', '30 Yard Pass',\n",
              "       '-8 Yard Sack', '51 Yard Pass', '37 Yard Pass', '-8 Yard Run',\n",
              "       'Turnover on Downs', '19 Yard Pass', '23 Yard Pass', '-7 Yard Run',\n",
              "       '11 Yard Run', '11 Yard Pass', '-7 Yard Sack', '-4 Yard Pass',\n",
              "       '-11 Yard Sack', '-6 Yard Run', 'Touchdown Bears',\n",
              "       '2PT Conversion Success', '2PT Conversion Fails',\n",
              "       'Touchdown Colts', '35 Yard Pass', '-5 Yard Sack',\n",
              "       '15 Yard Penalty', '-14 Yard Run', '-1 Yard Sack', '-3 Yard Pass',\n",
              "       'Touchdown Jaguars', '29 Yard Pass', '22 Yard Run',\n",
              "       '18 Yard Penalty', 'Field Goal No Good', '-1 Yard Pass',\n",
              "       '17 Yard Run', '19 Yard Run', 'Touchdown Browns', '33 Yard Pass',\n",
              "       '16 Yard Run', 'Touchdown Chiefs', '25 Yard Pass', '34 Yard Pass',\n",
              "       '41 Yard Penalty', '21 Yard Pass', 'Touchdown Lions',\n",
              "       '-12 Yard Penalty', '18 Yard Run', '23 Yard Run',\n",
              "       'Pass for No Gain', 'Touchdown Cowboys', '49 Yard Pass',\n",
              "       '37 Yard Penalty', '25 Yard Run', '-4 Yard Sack', '-5 Yard Pass',\n",
              "       'Touchdown Ravens', '26 Yard Penalty', '1 Yard Penalty',\n",
              "       '17 Yard Penalty', '17 Yard Pass', '-6 Yard Sack', '-6 Yard Pass',\n",
              "       '27 Yard Pass', '45 Yard Pass', 'Touchdown Saints', '41 Yard Pass',\n",
              "       '46 Yard Pass', 'Touchdown Raiders', '16 Yard Penalty',\n",
              "       '31 Yard Pass', 'Touchdown Broncos', 'Extra Point No Good',\n",
              "       '-7 Yard Pass', 'Touchdown Falcons', '-13 Yard Sack',\n",
              "       '21 Yard Run', '-7 Yard Penalty', '-4 Yard Penalty',\n",
              "       'Touchdown Panthers', '9 Yard Penalty', '4 Yard Penalty',\n",
              "       'Touchdown Buccaneers', '20 Yard Run', 'Touchdown Vikings',\n",
              "       '42 Yard Pass', '36 Yard Pass', 'Touchdown Chargers',\n",
              "       '55 Yard Run', '13 Yard Penalty', 'Penalty', 'Touchdown Dolphins',\n",
              "       '28 Yard Pass', '30 Yard Penalty', '47 Yard Pass',\n",
              "       'Touchdown Patriots', '32 Yard Pass', 'Touchdown Eagles',\n",
              "       '-14 Yard Penalty', 'Touchdown Rams', '-15 Yard Penalty',\n",
              "       '44 Yard Pass', '10 Yard Penalty', 'Touchdown Seahawks',\n",
              "       '15 Yard Run', '3 Yard Penalty', 'Touchdown 49ers', '39 Yard Run',\n",
              "       'Touchdown Steelers', '11 Yard Penalty', '29 Yard Run',\n",
              "       'Touchdown Cardinals', 'Touchdown Commanders'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE:\n",
        "# There are more play types that I have not made yet for Week 1.\n",
        "\n",
        "# Eyeing at all unique play outcomes to categorizing them.\n",
        "# - This type of approach does not feel very flexable because a play outcome can\n",
        "#   arise that has not been seen yet.\n",
        "# - There may be more in the future when working on a full season, let alone all seasons and future games\n",
        "\n",
        "# Play Types Complete\n",
        "df_2023_pass_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Pass')]\n",
        "df_2023_run_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Run')]\n",
        "df_2023_interception_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Interception')]\n",
        "\n",
        "\n",
        "\n",
        "# Play Types currently working on\n",
        "df_2023_touchdown_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "df_2023_sack_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Sack')] # <-- Next\n",
        "\n",
        "\n",
        "\n",
        "# Play types need to work on\n",
        "# df_2023_punt_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Punt')]\n",
        "\n",
        "# df_2023_kickoff_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Kickoff')]\n",
        "# df_2023_fumble_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Fumble')]\n",
        "# df_2023_penalty_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Penalty')]\n",
        "# df_2023_fieldgoal_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Field Goal')]\n",
        "# df_2023_extrapoint_week1 = week1_2023_plays[week1_2023_plays['PlayOutcome'].str.contains('Extra Point')]\n",
        "\n",
        "# plays_list = [df_2023_pass_sb,\n",
        "#               df_2023_run_sb,\n",
        "#               df_2023_punt_sb,\n",
        "#               df_2023_sack_sb,\n",
        "#               df_2023_kickoff_sb,\n",
        "#               df_2023_fumble_sb,\n",
        "#               df_2023_interception_sb,\n",
        "#               df_2023_penalty_sb,\n",
        "#               df_2023_fieldgoal_sb,\n",
        "#               df_2023_touchdown_sb,\n",
        "#               df_2023_extrapoint_sb]"
      ],
      "metadata": {
        "id": "sYCiceyQRrxl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SANITY CHECK (All Plays Accounted for)\n",
        "- NOT COMPLETE\n",
        "  - Still need to grab other play types\n",
        "    - Once all plays have been categorizing, will compare the sum to the size of the original dataframe of plays"
      ],
      "metadata": {
        "id": "ELSW1R82_TqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty for now."
      ],
      "metadata": {
        "id": "PcD7xXS03qBu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HELPER METHODS (personal use)\n",
        "- For personal use, does not actually take part in cleaning dataset at all."
      ],
      "metadata": {
        "id": "uau4ner4_fug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Quick look at a section of plays\n",
        "#   - Ideally the plays that the user wants to break down and clean.\n",
        "# INPUT PARAMETERS:\n",
        "# df_all_plays      - DataFrame - The original dataframe where the desired plays to view came from\n",
        "# df_section_plays  - DataFrame - A section of the original dataframe the user wants to view\n",
        "# RETURN:\n",
        "# - Printing to the console:\n",
        "#   1. index of play\n",
        "#   2. 'PlayDescription' feature of play\n",
        "#   3. 'PlayOutcome' feature of play\n",
        "def print_plays(df_all_plays, df_section_plays):\n",
        "  for idx, value in df_section_plays['PlayOutcome'].items():\n",
        "    play = df_all_plays['PlayDescription'].iloc[idx]\n",
        "    print(\"index:\" + str(idx))\n",
        "    for i in play.split(\". \"):\n",
        "      print(i)\n",
        "    print(value)\n",
        "    print()"
      ],
      "metadata": {
        "id": "u8Sza2J8_hwG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIPELINE\n",
        "  - ORDER\n",
        "    1. Regular expressions\n",
        "      - Used to find common patterns within raw data\n",
        "    1. Cleaning methods\n",
        "      - Unique cleaning methods for each play type\n",
        "        - Some methods may include helper methods\n",
        "    2. Main pipeline method\n",
        "      - Control flow of cleaning methods\n",
        "\n"
      ],
      "metadata": {
        "id": "AkZ2lDw3yF4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. REGULAR EXPRESSIONS"
      ],
      "metadata": {
        "id": "XksC21RH41fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "# REGULAR EXPRESSIONS USED TO LOCATE SPECIFIC DATA #\n",
        "####################################################\n",
        "\n",
        "################\n",
        "# PLAY DETAILS #\n",
        "################\n",
        "\n",
        "time_on_clock_pattern = r'\\((\\d*:\\d+)\\)'\n",
        "formation = r'\\(([A-Za-z]+ ?[A-Za-z]*,? ?[A-Za-z]*)\\)'\n",
        "yardage_gained = r'for (-?[0-9]+) yards?'\n",
        "yardage_from_sack = r'sacked(?: ob)? at(?: [A-Z]+)? [0-9]+ for (-?[0-9]+) yards'\n",
        "\n",
        "#################\n",
        "# NAMES OFFENSE #\n",
        "#################\n",
        "\n",
        "name_pattern = \"(?:[A-Za-z]+-)*[A-Za-z]+\\.[A-Za-z]+(?:-[A-Za-z]+)*\"\n",
        "passer_name_pattern = f\"({name_pattern}) pass\" # All passers are exclusively followed by ' pass'\n",
        "sacked_passer_name_pattern = f\"({name_pattern}) sacked\" # All sacked passers are exclusively followed by ' sacked'\n",
        "receiver_name_pattern = f\"to ({name_pattern})\" # All receivers exclusively follow 'to '\n",
        "intended_receiver_name_pattern = f\"intended for ({name_pattern})\" # intended receiver on an intercepted play\n",
        "rusher_pattern = f\"({name_pattern})(?: scrambles)? (?:left|right|up|kneels|Aborted|FUMBLES).?\"\n",
        "\n",
        "#################\n",
        "# NAMES DEFENSE #\n",
        "#################\n",
        "\n",
        "defense_tackler_1_name_pattern = f\"\\(({name_pattern})\" # Will have a \"(\" in front of the name / Also used to grab players that sacked passer\n",
        "defense_tackler_2_name_pattern = f\" ({name_pattern})\\)\" # Will have a \")\" at the end of the name\n",
        "# MIGHT NEED TO CHANGE:\n",
        "# - I think it might be possible for multiple defenders to apply pressure to the passer.\n",
        "defense_pressure_name_pattern = f\"\\[({name_pattern})\\]\" # Surrounded by \"[]\" brackets\n",
        "interception_name_pattern = f\"INTERCEPTED by ({name_pattern})\"\n",
        "split_sack_pattern = f\"sack split by ({name_pattern}) and ({name_pattern})\"\n",
        "\n",
        "#######################\n",
        "# PATTERNS ON FUMBLES #\n",
        "#######################\n",
        "\n",
        "qb_fumble = f\" ({name_pattern}) to(?: [A-Z]+) [0-9]+ for -?[0-9]+ yards$\" # Passer fumbles are always the initial action on the play,\n",
        "#                                                                           will have time displayed before action and possibly formation too\n",
        "forced_fumble_sentence = f\"FUMBLES \\({name_pattern}\\)\"\n",
        "run_after_recovery = f\"^({name_pattern}) to(?: [A-Z]+) [0-9]+ for \" # yardage after recovery (formatted almost exactly like a regular run play)\n",
        "run_after_interception = f\"({name_pattern}) (?:pushed ob at|ran ob at|to)(?: [A-Z]+)? [0-9]+ for \" # yardage after interception\n",
        "touchdown_after_interception = f\"({name_pattern}) for [0-9]+ yards, TOUCHDOWN\" # touchdown after interception\n",
        "\n",
        "##############\n",
        "#  INJURIES  #\n",
        "##############\n",
        "\n",
        "injury = f\"[A-Z]+-({name_pattern}) was injured during the play\" # Returns the player(s) who go injuried during play"
      ],
      "metadata": {
        "id": "7GjwQpriPJcS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. CLEANING METHODS"
      ],
      "metadata": {
        "id": "8LYvErx95uaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pass helper method (Fumbles)\n"
      ],
      "metadata": {
        "id": "DsERZOWJskje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR PASSING ONLY RIGHT NOW\n",
        "# - A possible goal down the road is to create a single method that can handle\n",
        "#   all fumble situations, whether it be a running fumble or a passing fumble.\n",
        "\n",
        "# PURPOSE:\n",
        "# - Extract fumble data from fumbled plays.\n",
        "#   - The goal is to strictly grab data that can only appear during fumbled plays,\n",
        "#     while attempting to push all commonly formated play type data to main cleaning methods.\n",
        "\n",
        "# NOTE:\n",
        "# - It is common for a single fumbled play row to be divided into multiple rows.\n",
        "#   - For example, an intended play has been fumbled and a player recoveres the fumble for a touchdown.\n",
        "#     - This will be split into 2 separate rows, (1) the intended play row and (2) the fumble recovery row.\n",
        "#   - The concern here is making sure those rows within the main dataframe of\n",
        "#     plays are tied together in some way, to signify that the multiple rows\n",
        "#     are not different plays but all instances of the same.\n",
        "#     - A solution here could be the features the multi play rows share.\n",
        "#       - For example, (TimeOnTheClock, Week, Quarter, DriveNumber, PlayNumberInDriver, etc..)\n",
        "\n",
        "#####################################################\n",
        "# ROUGH DESIGN OF SINGLE ROW PLAY -> MULTI ROW PLAY #\n",
        "#####################################################\n",
        "\n",
        "# - SINGLE PLAY ROW TO SINGLE PLAY ROW(S) METHOD:\n",
        "#   1. Split play into appropriate divisions (e.g. 1 row -> 3 rows)\n",
        "#      a. (row 1) - passer fumble\n",
        "#      b. (row 2) - passing play\n",
        "#      c. (row 3) - recovery for yardage\n",
        "#      NOTE:\n",
        "#      - These are all instances that call for a split\n",
        "#      - This will always be the cronological order\n",
        "#        - Any row out of these can be missing depending on the play.\n",
        "#   2. Clean each row individually\n",
        "#      1. Transform data into individual single row dataframes\n",
        "#      2. Run each row through appropriate cleaning method (e.i. passing, running, ...)\n",
        "#   3. Organize rows cronologically\n",
        "#      1. Create single dataframe containing all individual rows\n",
        "\n",
        "# - REPLACING PLAY WITHIN MAIN DATAFRAME:\n",
        "#   1. return single play multi row dataframe(?)\n",
        "#      -> MAIN CLEANING METHOD:\n",
        "#         1. replace original play row with new single play multi rows\n",
        "#            1. identify index of original play\n",
        "#            2. break main dataframe in 2 pieces\n",
        "#               a. Dataframe 1 - dataframe before index (exclusive)\n",
        "#               a. Dataframe 2 - dataframe after index (exclusive)\n",
        "#            3. concat new dataframe (Dataframe 1 +\n",
        "#                                     single play multi row dataframe +\n",
        "#                                     Dataframe 2)\n",
        "#         2. rerun main cleaning method (recursion)\n",
        "#            - manually insert index after last added row to pick up where it left off\n",
        "#            - exit case will be when the last passing type play has been cleaned\n",
        "\n",
        "##########################\n",
        "# EXAMPLE PLAY BREAKDOWN #\n",
        "##########################\n",
        "\n",
        "# PLAY (WITH NOTES):\n",
        "# (14:21) J.Love to CHI 44 for -3 yards <- signal for an additional row needed (passer fumble: grabbing passer name and yardage)\n",
        "# FUMBLES, and recovers at CHI 46 <- added to play feature 'FumbleDetails'\n",
        "# J.Love pass deep left to L.Musgrave to CHI 4 for 37 yards (T.Stevenson) [D.Walker]. <- pass to main breakdown method (follows traditional passing play format)\n",
        "# NOTE:\n",
        "# - If the fumble was to be recovered and ran for yardage, that would also call for an additional row needed.\n",
        "# EXAMPLE:\n",
        "# (4:45) (Shotgun) D.Jones pass short left to M.Breida to NYG 43 for 5 yards (M.Bell)\n",
        "# FUMBLES (M.Bell), recovered by NYG-P.Campbell at NYG 35\n",
        "# P.Campbell to NYG 33 for -2 yards <- signal for an additional row needed (fumble recovery for yards: grabbing player who recovered and yardage)\n",
        "# Officially, a pass for -3 yards.\n",
        "\n",
        "def extract_fumble_data_pass(df_plays, play, play_index):\n",
        "\n",
        "  # Separating each sentence within 'PlayDescription' (each sentence represents a single action)\n",
        "  play_elements = play.split(\". \")\n",
        "  # Collecting fumble data in the exact order in which it happened.\n",
        "  extracted_fumble_details = [None] * len(play_elements)\n",
        "  back_to_main_cleaning_method = []\n",
        "\n",
        "  # list for plays that need multiple rows\n",
        "  multi_row_play = []\n",
        "  # lists to collect distinct actions that will become their own rows\n",
        "  passer_fumble = []\n",
        "  fumble_recovery = []\n",
        "\n",
        "  for i in play_elements:\n",
        "    # Assume everything is going back to main cleaning method\n",
        "    back_to_main_cleaning_method.append(i)\n",
        "\n",
        "    # Passer fumble\n",
        "    # 1. Isolate the passer fumble action. (Take out of list going back to main cleaning method)\n",
        "    # 2. create new row (dataframe) with passer fumble action\n",
        "    # 3. clean newly created row (dataframe)\n",
        "    #    - QUESTION: Should 'PlayType' remain as 'pass' or should it be something else..?\n",
        "    #      - For now it will be 'run'.\n",
        "    # 4. append newly created row to 'passer_fumble'\n",
        "    #    - will be a list of single row dataframes (only expecting this list to have 1 element)\n",
        "    #    - POTENTIAL ERROR:\n",
        "    #      - qb_fumble I believe will not pick up REVERSED plays that initially start with a qb fumble.\n",
        "    passer_fumble_action = re.findall(qb_fumble, i)\n",
        "    if len(passer_fumble_action) > 0:\n",
        "      # 1. Isolate the passer fumble action. (Take out of list going back to main cleaning method)\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      # 2. create new row (dataframe) with passer fumble action\n",
        "      passer_fumble_row = df_plays.iloc[play_index].copy()\n",
        "      passer_fumble_row['PlayDescription'] = i\n",
        "      passer_fumble_row = pd.DataFrame([passer_fumble_row], columns=df_plays.columns)\n",
        "      # 3. clean newly created row (dataframe)\n",
        "      passer_fumble_row['PlayOutcome'] = 'Run' # <- This is ugly. Without this, the cleaning method for run plays will not clean.\n",
        "      cleaned_passer_fumble_row = clean_run_plays(passer_fumble_row)\n",
        "      cleaned_passer_fumble_row['PlayOutcome'] = df_plays.at[play_index, 'PlayOutcome'] # <- This is ugly.\n",
        "      #                                                                                      Switching 'PlayOutcome' back to it's shared value\n",
        "      #                                                                                      with the rest of the grouped rows representing the play.\n",
        "      # 4. append newly created row to 'passer_fumble'\n",
        "      passer_fumble.append(cleaned_passer_fumble_row)\n",
        "\n",
        "    # Fumble sentences to (fumble details)\n",
        "    if i.find('FUMBLES') != -1:\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      extracted_fumble_details.pop(play_elements.index(i))\n",
        "      extracted_fumble_details.insert(play_elements.index(i), i)\n",
        "\n",
        "    # Recovery for yardage\n",
        "    # 1. Isolate the recovery for yardage action\n",
        "    # 2. create new row (dataframe) with recovery for yardage action\n",
        "    # 3. clean newly created row (dataframe)\n",
        "    # 4. append newly created row to 'fumble_recovery'\n",
        "    fumble_recovery_action = re.findall(run_after_recovery, i)\n",
        "    if len(fumble_recovery_action) > 0:\n",
        "      # 1. Isolate the recovery for yardage action\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      # 2. create new row (dataframe) with recovery for yardage action\n",
        "      fumble_recovery_row = df_plays.iloc[play_index].copy()\n",
        "      fumble_recovery_row['PlayDescription'] = i\n",
        "      fumble_recovery_row = pd.DataFrame([fumble_recovery_row], columns=df_plays.columns)\n",
        "      # 3. clean newly created row (dataframe)\n",
        "      fumble_recovery_row['PlayOutcome'] = 'Run' # <- This is ugly. Without this, 'clean_run_plays' will not clean.\n",
        "      cleaned_fumble_recovery_row = clean_run_plays(fumble_recovery_row)\n",
        "      cleaned_fumble_recovery_row['PlayOutcome'] = df_plays.at[play_index, 'PlayOutcome'] # <- This too is ugly.\n",
        "      #                                                                                             Switching 'PlayOutcome' back to it's shared value\n",
        "      #                                                                                             with the rest of the grouped rows representing the play.\n",
        "      # 4. append newly created row to 'fumble_recovery'\n",
        "      fumble_recovery.append(cleaned_fumble_recovery_row)\n",
        "\n",
        "  ##################################################\n",
        "  # COMBINING ROWS FOR PLAYS THAT REQUIRE MULTIPLE #\n",
        "  ##################################################\n",
        "\n",
        "  # Check to see if additional rows are needed (e.i. if there are any elements within these 2 lists)\n",
        "  if len(passer_fumble) + len(fumble_recovery) > 0:\n",
        "    # Creating and cleaning row for intended play\n",
        "    # - Cleaning all data that was going to be sent back to the main cleaning method\n",
        "    main_play_row = df_plays.iloc[play_index].copy()\n",
        "    main_play_row['PlayDescription'] = '. '.join(back_to_main_cleaning_method)\n",
        "    main_play_row = pd.DataFrame([main_play_row], columns=df_plays.columns)\n",
        "    cleaned_main_play_row = clean_pass_plays(main_play_row)\n",
        "    # Organize rows cronologically\n",
        "    # 1. (row 1) - passer fumble\n",
        "    # 2. (row 2) - passing play\n",
        "    # 3. (row 3) - recovery for yardage\n",
        "    multi_row_play.extend(passer_fumble)\n",
        "    multi_row_play.append(cleaned_main_play_row)\n",
        "    multi_row_play.extend(fumble_recovery)\n",
        "    # Creating dataframe to group the divided single play rows\n",
        "    df_split_single_play = pd.DataFrame(columns=df_plays.columns)\n",
        "    # Iterate through each row and add to dataframe\n",
        "    for i in multi_row_play:\n",
        "      # Add the single play's 'FumbleDetails' to each row\n",
        "      if len(extracted_fumble_details) > 0:\n",
        "        # 'multi_row_play' is a list full of single row dataframes.\n",
        "        # - This means that there is only one index for every dataframe within 'multi_row_play'\n",
        "        row_index = i.index[0]\n",
        "        i.at[row_index, 'FumbleDetails'] = extracted_fumble_details\n",
        "      # Combining each row, all peices of a single play, into a dataframe\n",
        "      if df_split_single_play.empty:\n",
        "        df_split_single_play = i # Pandas depricating the ability to concat an empty dataframe with one that is not.\n",
        "      else:\n",
        "        df_split_single_play = pd.concat([df_split_single_play, i], ignore_index=True)\n",
        "    return None, None, df_split_single_play\n",
        "\n",
        "  # returning empty dataframe because there will be zero additional rows added\n",
        "  return extracted_fumble_details, back_to_main_cleaning_method, pd.DataFrame()"
      ],
      "metadata": {
        "id": "CWmHZUK6R9Om"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PASS PLAYS"
      ],
      "metadata": {
        "id": "9L_L6vxtmnLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean all passing type plays within a given dataframe.\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - NFL plays (can include play types other than passing)\n",
        "# index_start -  integer  - index where within the dataframe the method will start\n",
        "#                           cleaning in ascending order.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - the same df_plays input but with all passing play types cleaned\n",
        "\n",
        "def clean_pass_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Adjusting df_plays to start cleaning at a specified index (index_start)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Pass')]\n",
        "  else:\n",
        "    # Locating all passing type plays within dataframe\n",
        "    df_pass_plays = df_plays[df_plays['PlayOutcome'].str.contains('Pass')]\n",
        "\n",
        "  for idx, play in df_pass_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Pass'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    # Additional rows may be added after certain types of fumbled passing plays.\n",
        "    # - The idea here is that, in those situations, the helping method 'extract_fumble_data_pass'\n",
        "    #   will return a small dataframe of the rows that the single play split into.\n",
        "    #   - When this small dataframe is returned, it will need to replace the original play\n",
        "    #     within the main dataframe of plays and then continue on cleaning the rest of the passing plays.\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "      fumble_details, play, df_added_rows = extract_fumble_data_pass(df_plays, play, idx)\n",
        "      if not df_added_rows.empty:\n",
        "        df_before = df_plays.iloc[:idx]\n",
        "        df_after = df_plays.iloc[idx+1:]\n",
        "        df_plays = pd.concat([df_before, df_added_rows, df_after], ignore_index=True)\n",
        "        index_of_last_added_row = idx + len(df_added_rows) - 1\n",
        "        return clean_pass_plays(df_plays, index_of_last_added_row)\n",
        "\n",
        "      df_plays.at[idx, 'FumbleDetails'] = fumble_details\n",
        "      play = \". \".join(play)\n",
        "\n",
        "    ###########\n",
        "    # OFFENSE #\n",
        "    ###########\n",
        "\n",
        "    # NOTE:\n",
        "    # - Incomplete passes will have 'PlayOutcome' as 'Pass Incomplete' as well\n",
        "    #   as yardage value being 0.0\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    else:\n",
        "      df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Passer (What about spikes?)\n",
        "    passer_name = re.findall(passer_name_pattern, play)\n",
        "    if len(passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = passer_name[0]\n",
        "\n",
        "    # Pass Type\n",
        "    if play.find('deep') != -1:\n",
        "      df_plays.loc[idx, 'PassType'] = 'Deep'\n",
        "    elif play.find('short') != -1:\n",
        "      df_plays.loc[idx, 'PassType'] = 'Short'\n",
        "\n",
        "    # Pass Direction\n",
        "    if play.find('left') != -1:\n",
        "      df_plays.loc[idx, 'Direction'] = 'Left'\n",
        "    elif play.find('right') != -1:\n",
        "      df_plays.loc[idx, 'Direction'] = 'Right'\n",
        "    elif play.find('middle') != -1:\n",
        "      df_plays.loc[idx, 'Direction'] = 'Middle'\n",
        "\n",
        "    # Unique situation (offense spikes the ball)\n",
        "    if play.find('spike') != -1:\n",
        "      df_plays.loc[idx, 'PassType'] = 'Spike'\n",
        "      df_plays.loc[idx, 'Passer'] = re.findall(name_pattern, play)[0]\n",
        "\n",
        "    # Receiver\n",
        "    receiver_names = re.findall(receiver_name_pattern, play)\n",
        "    if len(receiver_names) > 0:\n",
        "      df_plays.loc[idx, 'Receiver'] = receiver_names[0]\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Difference between \", \" and \"; \" separating tacklers\n",
        "    # ', ' - both defenders worked together to make the tackle\n",
        "    # \"; \" - first defender initiated hit and second finished\n",
        "    # - Should I mark the differences?\n",
        "\n",
        "    tackler_1 = re.findall(defense_tackler_1_name_pattern, play) # tackler #1 (Could be solo or the one who initiated the hit)\n",
        "    if len(tackler_1) > 0:\n",
        "      df_plays.loc[idx, 'TackleBy1'] = tackler_1[0]\n",
        "\n",
        "    tackler_2 = re.findall(defense_tackler_2_name_pattern, play) # tackler #2 (equally contributed or assisted with tackle)\n",
        "    if len(tackler_2) > 0:\n",
        "      df_plays.loc[idx, 'TackleBy2'] = tackler_2[0]\n",
        "\n",
        "    pressure_by = re.findall(defense_pressure_name_pattern, play) # defender who applied pressure to the passer\n",
        "    if len(pressure_by) > 0:\n",
        "      df_plays.loc[idx, 'PressureBy'] = pressure_by[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "  if df_pass_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays"
      ],
      "metadata": {
        "id": "sfPMYHLymueN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run helper method (Fumbles)\n",
        "- Goal might be to combine both pass and run helper methods for fumbles"
      ],
      "metadata": {
        "id": "K5cZryPjsnxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Extract fumble details and push back data from fumbled plays that can be broken\n",
        "#   down by the main play cleaning method.\n",
        "# INPUT PARAMTERS:\n",
        "# df_plays   - dataframe - dataframe of plays\n",
        "# play       -  string   - 'PlayDescription' of play that contains a fumble\n",
        "# play_index -  integer  - index of the fumbled play within 'df_plays'\n",
        "# RETURN (TUPLE):\n",
        "# extracted_fumble_details     -   list    - all details of the fumbled play that contain data\n",
        "#                                            that is of less importance\n",
        "#                                             - The reason for this is to save space. It does not\n",
        "#                                               make sense to have features for this data when\n",
        "#                                               1/100 plays will contain a fumble.\n",
        "# back_to_main_cleaning_method -   list    - All details of the fumbled play that can be broken\n",
        "#                                            down by the main play cleaning method.\n",
        "# df_split_single_play         - dataframe - When a single play needs to be split into separate rows,\n",
        "#                                            this will return a dataframe of that single play into split\n",
        "#                                            rows.\n",
        "\n",
        "def extract_fumble_data_run(df_plays, play, play_index):\n",
        "\n",
        "  # 'PlayDescription' is made up of a group of sentences, each containing individual actions of the play.\n",
        "  play_elements = play.split(\". \")\n",
        "  extracted_fumble_details = [None] * len(play_elements)\n",
        "  back_to_main_cleaning_method = []\n",
        "\n",
        "  # list for plays that need multiple rows\n",
        "  multi_row_play = []\n",
        "  # To collect distinct actions that will become their own rows\n",
        "  df_fumble_recovery = []\n",
        "\n",
        "  for i in play_elements:\n",
        "    # Assuming everything is going back to main cleaning method\n",
        "    back_to_main_cleaning_method.append(i)\n",
        "\n",
        "    # Aborted sentences to both (fumble details & main cleaning method)\n",
        "    if i.find('Aborted') != -1:\n",
        "      extracted_fumble_details.pop(play_elements.index(i))\n",
        "      extracted_fumble_details.insert(play_elements.index(i), i)\n",
        "      continue\n",
        "\n",
        "    # Fumble sentences to (fumble details)\n",
        "    if i.find('FUMBLES') != -1:\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      extracted_fumble_details.pop(play_elements.index(i))\n",
        "      extracted_fumble_details.insert(play_elements.index(i), i)\n",
        "\n",
        "    # Recovery for yardage\n",
        "    # 1. Isolate the recovery for yardage action (Take out of list going back to main cleaning method)\n",
        "    # 2. create new row (dataframe) with recovery for yardage action\n",
        "    # 3. clean newly created row (dataframe)\n",
        "    # 4. append newly created row to 'df_fumble_recovery'\n",
        "    fumble_recovery_action = re.findall(run_after_recovery, i)\n",
        "    if len(fumble_recovery_action) > 0:\n",
        "      # 1. Isolate the recovery for yardage action (Take out of list going back to main cleaning method)\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      # 2. create new row (dataframe) with recovery for yardage action\n",
        "      recovery_for_yardage_row = df_plays.iloc[play_index].copy()\n",
        "      recovery_for_yardage_row['PlayDescription'] = i\n",
        "      recovery_for_yardage_row = pd.DataFrame([recovery_for_yardage_row], columns=df_plays.columns)\n",
        "      # 3. clean newly created row (dataframe)\n",
        "      #    - Will clean without a problem because 'PlayOutcome' has 'Run' in its value.\n",
        "      cleaned_recovery_for_yardage_row = clean_run_plays(recovery_for_yardage_row)\n",
        "      # 4. append newly created row to 'df_fumble_recovery'\n",
        "      df_fumble_recovery.append(cleaned_recovery_for_yardage_row)\n",
        "\n",
        "  ##################################################\n",
        "  # COMBINING ROWS FOR PLAYS THAT REQUIRE MULTIPLE #\n",
        "  ##################################################\n",
        "\n",
        "  # Check to see if additional rows are needed (e.i. if there are any elements within the lists)\n",
        "  if len(df_fumble_recovery) > 0:\n",
        "    # Creating and cleaning row for intended play\n",
        "    main_play_row = df_plays.iloc[play_index].copy()\n",
        "    main_play_row['PlayDescription'] = '. '.join(back_to_main_cleaning_method)\n",
        "    main_play_row = pd.DataFrame([main_play_row], columns=df_plays.columns)\n",
        "    cleaned_main_play_row = clean_run_plays(main_play_row)\n",
        "\n",
        "    # Organize rows cronologically\n",
        "    # 1. (row 1) - running play\n",
        "    # 2. (row 2) - recovery for yardage\n",
        "    multi_row_play.append(main_play_row)\n",
        "    multi_row_play.extend(df_fumble_recovery)\n",
        "    # Creating dataframe to group the divided single play rows\n",
        "    df_split_single_play = pd.DataFrame(columns=df_plays.columns)\n",
        "    # Iterate through each row and add to dataframe\n",
        "    for i in multi_row_play:\n",
        "      if len(extracted_fumble_details) > 0:\n",
        "        # 'multi_row_play' is a list full of single row dataframes.\n",
        "        # - This means that there is only one index for every dataframe within 'multi_row_play'\n",
        "        row_index = i.index[0]\n",
        "        i.at[row_index, 'FumbleDetails'] = extracted_fumble_details\n",
        "      # Combining each row, all peices of a single play, into a dataframe\n",
        "      if df_split_single_play.empty:\n",
        "        df_split_single_play = i # Pandas depricating the ability to concat an empty dataframe with one that is not.\n",
        "      else:\n",
        "        df_split_single_play = pd.concat([df_split_single_play, i], ignore_index=True)\n",
        "\n",
        "    return None, None, df_split_single_play\n",
        "\n",
        "  # returning empty dataframe because there will be zero additional rows added\n",
        "  return extracted_fumble_details, back_to_main_cleaning_method, pd.DataFrame()"
      ],
      "metadata": {
        "id": "TMJe8OYWpUDm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RUN PLAYS"
      ],
      "metadata": {
        "id": "bRGsJa-J8CPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean run type plays\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning. (Needs to be the index of a run play)\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful run play\n",
        "#                        data accessable and clean.\n",
        "\n",
        "def clean_run_plays(df_plays, index_start = None):\n",
        "\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_run_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Run')]\n",
        "  else:\n",
        "    df_run_plays = df_plays[df_plays['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "  # Iterating through every run play within 'df_run_plays'\n",
        "  for idx, play in df_run_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # Play Type\n",
        "    df_plays.loc[idx, 'PlayType'] = 'Run'\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ############\n",
        "    # REVERSES #\n",
        "    ############\n",
        "\n",
        "    # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "    # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "    if play.find('REVERSED') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find(\"REVERSED\") != -1:\n",
        "          df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ############################\n",
        "    # REPORTING IN AS ELIGIBLE #\n",
        "    ############################\n",
        "\n",
        "    # I do not think this contains any useful data so I am going to exclude it.\n",
        "    if play.find('reported in as eligible') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      for i in play_elements:\n",
        "        if i.find('reported in as eligible') != -1:\n",
        "          play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "          break\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "      fumble_details, play, df_added_rows = extract_fumble_data_run(df_plays, play, idx)\n",
        "      if not df_added_rows.empty:\n",
        "        df_before = df_plays.iloc[:idx]\n",
        "        df_after = df_plays.iloc[idx+1:]\n",
        "        df_plays = pd.concat([df_before, df_added_rows, df_after], ignore_index=True)\n",
        "        index_of_last_added_row = idx + len(df_added_rows) - 1\n",
        "        return clean_run_plays(df_plays, index_of_last_added_row)\n",
        "\n",
        "      df_plays.at[idx, 'FumbleDetails'] = fumble_details\n",
        "      play = \". \".join(play)\n",
        "\n",
        "    # Yardage gained\n",
        "    yardage = re.findall(yardage_gained, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "    else:\n",
        "      df_plays.loc[idx, 'Yardage'] = 0\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Rusher\n",
        "    rusher_patterns = [rusher_pattern, run_after_recovery, qb_fumble]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        rusher_name = rusher[0]\n",
        "        break\n",
        "    df_plays.loc[idx, 'Rusher'] = rusher_name\n",
        "\n",
        "    # Direction\n",
        "    rushing_directions = ['guard', 'middle', 'tackle', 'end', 'kneels']\n",
        "    for i in rushing_directions:\n",
        "      if play.find(i) != -1:\n",
        "        start = play.find(rusher_name) + len(rusher_name) + 1\n",
        "        end = play.find(i) + len(i)\n",
        "        df_plays.loc[idx, 'Direction'] = play[start:end]\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    tackler_1 = re.findall(defense_tackler_1_name_pattern, play) # tackler #1 (Could be solo or the one who initiated the hit)\n",
        "    if len(tackler_1) > 0:\n",
        "      df_plays.loc[idx, 'TackleBy1'] = tackler_1[0]\n",
        "    tackler_2 = re.findall(defense_tackler_2_name_pattern, play) # tackler #2 (equally contributed or assisted with tackle)\n",
        "    if len(tackler_2) > 0:\n",
        "      df_plays.loc[idx, 'TackleBy2'] = tackler_2[0]\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "    # Return if the last play has been cleaned in 'df_run_plays'\n",
        "    if df_run_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays"
      ],
      "metadata": {
        "id": "9WiRg4pyDzqY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INTERCEPTIONS"
      ],
      "metadata": {
        "id": "CZpJpikZCx--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Clean intercepted plays\n",
        "# INPUT PARAMETERS:\n",
        "# df_plays    - dataframe - dataframe of plays\n",
        "# index_start -  integer  - the starting index of the associated input dataframe\n",
        "#                           to begin cleaning.\n",
        "# RETURN:\n",
        "# df_plays - dataframe - dataframe of plays that now has all useful intercepted play\n",
        "#                        data accessible and clean.\n",
        "\n",
        "# ROUGH DESGIN\n",
        "# 1. Narrow dataframe using 'index_start'\n",
        "#    - This is a recursive method, the narrowing will get smaller and\n",
        "#      smaller until all 'intercepted' type plays have been cleaned.\n",
        "# 2. Grab first 'intercepted' play from narrowed dataframe\n",
        "# 3. Create 2 single row dataframes.\n",
        "#    a. intended play\n",
        "#    b. yardage after interception\n",
        "# 4. Break down play into sentences and clean\n",
        "#    - Depending on the sentence within the play, will determine which\n",
        "#      single row dataframe it will go to.\n",
        "# 5. Combine both dataframes of cleaned data into one dataframe\n",
        "# 6. Replace old play row with new cleaned multi row\n",
        "# 7. return clean_interceped_plays( x , y)\n",
        "#    - x = updated df_plays\n",
        "#    - y = index directly after the last clean added row\n",
        "\n",
        "# Concerns:\n",
        "# ~ 1 ~\n",
        "# PLAY SNIP - \"(9:53) (Shotgun) D.Watson pass short left intended for E.Moore INTERCEPTED by D.Hill (Z.Carter) at CIN 30.\"\n",
        "# - The concern here is (Z.Carter)\n",
        "#   - I do not know what to categorize this player as? I believe that he had an impact on the play and could possibly be a reason\n",
        "#     that D.Hill was able to intercept the ball.\n",
        "# ~ 2 ~\n",
        "# PLAY SNIP - \"(4:16) (Shotgun) J.Allen pass deep middle intended for S.Diggs INTERCEPTED by J.Whitehead [Q.Williams] at NYJ -1. Touchback.\"\n",
        "# - The concern here is 'touchback'\n",
        "#   - I have no idea what to do with that\n",
        "# ~ 3 ~\n",
        "#`- I do not have anything set in play to handle fumbles? What happens if a QB fumbles, recovers, then throws an interception? -> Then player that intercepted fumbles?\n",
        "# ~ 4 ~\n",
        "# - There are 2 rows within this sinlge play. (Intended throwing play, yardage after interception)\n",
        "#   - For both of these rows that represent a single play, they both state that the throwing team has possession\n",
        "#     - I do not know how this is going to effect the future with analysis on data\n",
        "\n",
        "def clean_intercepted_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_intercepted_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Interception')]\n",
        "  else:\n",
        "    df_intercepted_plays = df_plays[df_plays['PlayOutcome'].str.contains('Interception')]\n",
        "\n",
        "  # Exit case (If no more 'Interception' type plays are found)\n",
        "  if df_intercepted_plays.empty:\n",
        "    return df_plays\n",
        "\n",
        "  # Retrieve the index and 'PlayDescription' of the first interception play in 'df_intercepted_plays'\n",
        "  # - Process one play per iteration in the recursive method\n",
        "  idx = df_intercepted_plays.index[0]\n",
        "  play = df_plays['PlayDescription'].iloc[idx]\n",
        "  # play = df_plays['PlayDescription'].iloc[df_plays.index.tolist().index(idx)]\n",
        "\n",
        "  ############\n",
        "  # REVERSES #\n",
        "  ############\n",
        "\n",
        "  # In 'PlayDescription' all information before the \"reversed\" sentence is not needed.\n",
        "  # - All information before is stored within 'ReverseDetails' and the remaining is cleaned.\n",
        "  if play.find('REVERSED') != -1:\n",
        "    play_elements = play.split(\". \")\n",
        "    for i in play_elements:\n",
        "      if i.find(\"REVERSED\") != -1:\n",
        "        df_plays.at[idx, 'ReverseDetails'] = play_elements[:play_elements.index(i) + 1]\n",
        "        play = \". \".join(play_elements[play_elements.index(i) + 1:])\n",
        "        break\n",
        "\n",
        "  # Create 2 single row dataframes.\n",
        "  # 1. intended play\n",
        "  df_intended_play = df_plays.iloc[idx].copy()\n",
        "  df_intended_play = pd.DataFrame([df_intended_play], columns=df_plays.columns)\n",
        "  df_intended_play.reset_index(drop=True, inplace=True)\n",
        "  df_intended_play['PlayDescription'] = 'nan'\n",
        "  # 2. yardage after interception\n",
        "  df_yardage_after_interception = df_plays.iloc[idx].copy()\n",
        "  df_yardage_after_interception = pd.DataFrame([df_yardage_after_interception], columns=df_plays.columns)\n",
        "  df_yardage_after_interception.reset_index(drop=True, inplace=True)\n",
        "  df_yardage_after_interception['PlayDescription'] = 'nan'\n",
        "\n",
        "  # break down play by sentences.\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  # iterate through play_elements\n",
        "  for i in play_elements:\n",
        "\n",
        "    ##############################\n",
        "    # YARDAGE AFTER INTERCEPTION #\n",
        "    ##############################\n",
        "\n",
        "    yardage_after_interception = re.findall(run_after_interception, i)\n",
        "    if len(yardage_after_interception) > 0:\n",
        "      df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "      # Player running after interception\n",
        "      df_yardage_after_interception.loc[0, 'Rusher'] = yardage_after_interception[0]\n",
        "\n",
        "      # Playtype?\n",
        "      # - Should this be a new playtype? Something like \"RunAfterInterception\"?\n",
        "\n",
        "      # Yardage gained\n",
        "      yardage = re.findall(yardage_gained, i)\n",
        "      if len(yardage) > 0:\n",
        "        df_yardage_after_interception.loc[0, 'Yardage'] = int(yardage[0])\n",
        "      else:\n",
        "        df_yardage_after_interception.loc[0, 'Yardage'] = 0\n",
        "\n",
        "      # Who made tackle\n",
        "      tackler = re.findall(defense_tackler_1_name_pattern, i)\n",
        "      if len(tackler) > 0:\n",
        "        df_yardage_after_interception.loc[0, 'TackleBy1'] = tackler[0]\n",
        "\n",
        "      continue\n",
        "\n",
        "    ################################\n",
        "    # TOUCHDOWN AFTER INTERCEPTION #\n",
        "    ################################\n",
        "\n",
        "    touchdown_after_interception_check = re.findall(touchdown_after_interception, i)\n",
        "    if len(touchdown_after_interception_check) > 0:\n",
        "      df_yardage_after_interception['PlayDescription'] = i\n",
        "\n",
        "      # Player running after interception\n",
        "      df_yardage_after_interception.loc[0, 'Rusher'] = touchdown_after_interception_check[0]\n",
        "\n",
        "      # Yardage gained\n",
        "      yardage = re.findall(yardage_gained, i)\n",
        "      if len(yardage) > 0:\n",
        "        df_yardage_after_interception.loc[0, 'Yardage'] = int(yardage[0])\n",
        "\n",
        "      # PlayOutcome\n",
        "      df_yardage_after_interception.loc[0, 'PlayOutcome'] = 'Touchdown'\n",
        "\n",
        "      # IsScoringPlay\n",
        "      df_yardage_after_interception.loc[0, 'IsScoringPlay'] = 1\n",
        "\n",
        "      continue\n",
        "\n",
        "\n",
        "    #################\n",
        "    # INTENDED PLAY #\n",
        "    #################\n",
        "\n",
        "    passer_name = re.findall(passer_name_pattern, i)\n",
        "    if len(passer_name) > 0:\n",
        "      df_intended_play['PlayDescription'] = i\n",
        "\n",
        "      # passer\n",
        "      df_intended_play.loc[0, 'Passer'] = passer_name[0]\n",
        "\n",
        "      # Play type\n",
        "      df_intended_play.loc[0, 'PlayType'] = 'Pass'\n",
        "\n",
        "      # TimeOnTheClock\n",
        "      TimeOnTheClock = re.findall(time_on_clock_pattern, i)\n",
        "      if len(TimeOnTheClock) > 0:\n",
        "        df_intended_play.loc[0, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "      # Formation\n",
        "      Formation = re.findall(formation, i)\n",
        "      if len(Formation) > 0:\n",
        "          df_intended_play.loc[0, 'Formation'] = Formation[0]\n",
        "\n",
        "      # Pass Type\n",
        "      if i.find('deep') != -1:\n",
        "        df_intended_play.loc[0, 'PassType'] = 'Deep'\n",
        "      elif i.find('short') != -1:\n",
        "        df_intended_play.loc[0, 'PassType'] = 'Short'\n",
        "\n",
        "      # Pass Direction\n",
        "      if i.find('left') != -1:\n",
        "        df_intended_play.loc[0, 'Direction'] = 'Left'\n",
        "      elif i.find('right') != -1:\n",
        "        df_intended_play.loc[0, 'Direction'] = 'Right'\n",
        "      elif i.find('middle') != -1:\n",
        "        df_intended_play.loc[0, 'Direction'] = 'Middle'\n",
        "\n",
        "      # Receiver\n",
        "      intended_receiver_name = re.findall(intended_receiver_name_pattern, i)\n",
        "      if len(intended_receiver_name) > 0:\n",
        "        df_intended_play.loc[0, 'Receiver'] = intended_receiver_name[0]\n",
        "\n",
        "      # PressureBy\n",
        "      pressure_by = re.findall(defense_pressure_name_pattern, i)\n",
        "      if len(pressure_by) > 0:\n",
        "        df_intended_play.loc[0, 'PressureBy'] = pressure_by[0]\n",
        "\n",
        "      # Intercepted by\n",
        "      intercepted_by = re.findall(interception_name_pattern, i)\n",
        "      if len(intercepted_by) > 0:\n",
        "        df_intended_play.loc[0, 'InterceptedBy'] = intercepted_by[0]\n",
        "\n",
        "      continue\n",
        "\n",
        "    # - All other data, add to both dataframes\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury, i)\n",
        "    if len(injuries) > 0:\n",
        "      df_intended_play.at[0, 'InjuredPlayers'] = injuries\n",
        "      df_yardage_after_interception.at[0, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Look at the value within penalty.\n",
        "    # if there is nothing there, add a list with the penalty as an element\n",
        "    # if there is something there, add to that list with the penalty as another element\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if i.find('PENALTY') != -1:\n",
        "      if df_intended_play['AcceptedPenalty'].iloc[0] == 'nan':\n",
        "        df_intended_play.at[0, 'AcceptedPenalty'] = [i]\n",
        "        df_yardage_after_interception.at[0, 'AcceptedPenalty'] = [i]\n",
        "      else:\n",
        "        df_intended_play.at[0, 'AcceptedPenalty'].append(i)\n",
        "        df_yardage_after_interception.at[0, 'AcceptedPenalty'].append(i)\n",
        "\n",
        "    # Declined Penalty\n",
        "    if i.find('Penalty') != -1:\n",
        "      if df_intended_play['DeclinedPenalty'].iloc[0] == 'nan':\n",
        "        df_intended_play.at[0, 'DeclinedPenalty'] = [i]\n",
        "        df_yardage_after_interception.at[0, 'DeclinedPenalty'] = [i]\n",
        "      else:\n",
        "        df_intended_play.at[0, 'DeclinedPenalty'].append(i)\n",
        "        df_yardage_after_interception.at[0, 'DeclinedPenalty'].append(i)\n",
        "\n",
        "  # combine both single row dataframes into one\n",
        "  if df_yardage_after_interception['PlayDescription'].iloc[0] == 'nan':\n",
        "    df_cleaned_replacement = df_intended_play\n",
        "  else:\n",
        "    df_cleaned_replacement = pd.concat([df_intended_play, df_yardage_after_interception], ignore_index=True)\n",
        "\n",
        "  # Replace old row with new cleaned dataframe\n",
        "  df_before_row = df_plays.iloc[:idx]\n",
        "  df_after_row = df_plays.iloc[idx+1:]\n",
        "  df_plays = pd.concat([df_before_row, df_cleaned_replacement, df_after_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  # If this is the last play in the dataset\n",
        "  if df_intercepted_plays.tail(1).index.tolist()[0] == idx:\n",
        "    return df_plays\n",
        "  else:\n",
        "    return clean_intercepted_plays(df_plays, idx+len(df_cleaned_replacement))"
      ],
      "metadata": {
        "id": "Hp4KSQcBC7Ew"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sack helper method (Fumbles)"
      ],
      "metadata": {
        "id": "IFsUxl8zZpZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 2\n",
        "# - Need to comment on how this is using a 2D list.\n",
        "\n",
        "def extract_fumble_data_sack(df_plays, play, play_index):\n",
        "\n",
        "  original_play_copy = df_plays.iloc[df_plays.index.tolist().index(play_index)]\n",
        "\n",
        "  # I need to break this play into its individual parts\n",
        "  play_elements = play.split(\". \")\n",
        "\n",
        "  # Goal for 'play_split' list:\n",
        "  # - This group of elements will represent a single play that will be separated into multiple rows\n",
        "  # - Each element within the list will represent a new row that will be added onto the original dataframe.\n",
        "  #   - Each element will have all data required for that new row\n",
        "  #   ROW CONTENTS:\n",
        "  #   1. ( The intended play ) + ( Who caused the fumble ) + ( Extra information ) <- This row will have extra info such as (injuries / penalties / eligibility / etc...)\n",
        "  # ~ 2. ( The fumble recovery ) + ( Who caused the fumble ) <- This could happen repeatedly or not at all\n",
        "\n",
        "  # I am now thinking that this should be a 2D list.\n",
        "  # - each element will look like this -> (play, who caused forced fumble)\n",
        "  play_split = []\n",
        "\n",
        "  # - Iterate through each element within play with access to it's index\n",
        "  for i, string in enumerate(play_elements):\n",
        "\n",
        "    # This will create a new element within the list when it comes across:\n",
        "    # 1. The intended play\n",
        "    # 2. The run after recovery\n",
        "    for play_pattern in [sacked_passer_name_pattern, run_after_recovery]:\n",
        "      if re.search(play_pattern, string) != None:\n",
        "        play_split.append([string]) # <- I am right here and confused. I need to create a list that will have either 1 or 2 length elements in its own elements.\n",
        "        break\n",
        "    if re.search(play_pattern, string) != None:\n",
        "      continue\n",
        "\n",
        "    # - A new row will be added when a play has occured. (intended play OR run after recovery)\n",
        "    #   - A forced fumble sentence will only appear directly after a play.\n",
        "    #     - I would like to tie together the PLAY and the FORCE FUMBLE SENTENCE together into a single row\n",
        "    #       - My approach for doing this is when iterating through each sentence and a force fumble\n",
        "    #         sentence has appeared, I will attach the forced fumble sentence to the last element within\n",
        "    #         the list (which should be the most recent play that occured since we are iterating\n",
        "    #         chronologically step by step through what has happened during the entire play)\n",
        "    forced_fumble = re.search(forced_fumble_sentence, string)\n",
        "    if forced_fumble != None:\n",
        "      if len(play_split) > 0:\n",
        "        index_last_element = len(play_split) - 1\n",
        "        play_split[index_last_element] = [play_split[index_last_element], string]\n",
        "        continue\n",
        "\n",
        "    # All additional data will be added to the first element within the list,\n",
        "    # which should be the intended play. (additional data includes: injuries, penalties, elibility, etc.)\n",
        "    if (len(play_split[0]) > 1):\n",
        "      play_split[0][0] = play_split[0][0] + \". \" + string\n",
        "    else:\n",
        "      play_split[0] = play_split[0] + \". \" + string\n",
        "\n",
        "  # for i, string in enumerate(play_elements):\n",
        "  #   print(string)\n",
        "\n",
        "  # for i, string in enumerate(play_split):\n",
        "  #   print(i)\n",
        "  #   print(string)\n",
        "\n",
        "  ####################\n",
        "  # LIST IS COMPLETE #\n",
        "  ####################\n",
        "\n",
        "  # I then need to create a dataframe with each of its rows, a separate element\n",
        "  # within the list.\n",
        "  # - While iterating through the list, I will clean each row so that the end\n",
        "  #   result will have a completely clean play.\n",
        "\n",
        "  # NEXT STEP (Cast elements in list as single row dataframes and clean)\n",
        "  # - Clean each element within the play_split list\n",
        "  #   - I need to clean intended play\n",
        "  #     - The first element should always be the intended play. Is this useful?\n",
        "  #   - The rest will be runs after recovery.\n",
        "  # STEPS:\n",
        "  # - How should I separate these plays?\n",
        "  #   - I am thinking of keeping them in the same list and taking advantage of the fact\n",
        "  #     that the intended play will always be the first element of the list.\n",
        "  # 1. Locate intended play (first in the list 'play_split')\n",
        "  # 2. clean intended play using the main cleaning method for playtype\n",
        "  # 3. when the intended play comes back, add additional data from here to play\n",
        "  #    - Such as who caused the forced fumble\n",
        "  # 4. cycle through the rest of the plays within 'play_split' and clean\n",
        "\n",
        "  # Should I have a check here to be sure that the intended play is actually the first element?\n",
        "  intended_play_description = play_split.pop(0)\n",
        "  intended_play_row = original_play_copy.copy()\n",
        "\n",
        "  if len(intended_play_description) > 1:\n",
        "    intended_play_row['PlayDescription'] = intended_play_description[0]\n",
        "    # This is where I will add 'forcedfumbleby' <- <- <- <- <- <- <- <-\n",
        "    # print(cleaned_intended_play_row['PlayDescription'])\n",
        "  else:\n",
        "    intended_play_row['PlayDescription'] = intended_play_description\n",
        "  intended_play_row = pd.DataFrame([intended_play_row], columns=df_plays.columns)\n",
        "  cleaned_intended_play_row = clean_sacked_plays(intended_play_row)\n",
        "\n",
        "  # List for\n",
        "  list_recovery_runs = []\n",
        "\n",
        "  for idx, play in enumerate(play_split):\n",
        "    print(idx)\n",
        "    print(play)\n",
        "    print(len(play_split[idx]))\n",
        "\n",
        "    recovery_run_row = original_play_copy.copy()\n",
        "\n",
        "    if len(play) > 1:\n",
        "      recovery_run_description = play[0]\n",
        "      recovery_run_row['PlayDescription'] = recovery_run_description\n",
        "      recovery_run_row['PlayOutcome'] = 'Run'\n",
        "      recovery_run_row = pd.DataFrame([recovery_run_row], columns=df_plays.columns)\n",
        "      cleaned_recovery_run_row = clean_run_plays(recovery_run_row)\n",
        "      cleaned_recovery_run_row['PlayOutcome'] = original_play_copy['PlayOutcome']\n",
        "      list_recovery_runs.append(cleaned_recovery_run_row)\n",
        "    else:\n",
        "      recovery_run_description = play\n",
        "      recovery_run_row['PlayDescription'] = recovery_run_description\n",
        "      recovery_run_row['PlayOutcome'] = 'Run'\n",
        "      recovery_run_row = pd.DataFrame([recovery_run_row], columns=df_plays.columns)\n",
        "      print(recovery_run_description)\n",
        "\n",
        "      rusher = re.search(run_after_recovery, recovery_run_description)\n",
        "      if rusher != None:\n",
        "        print(rusher)\n",
        "\n",
        "      cleaned_recovery_run_row = clean_run_plays(recovery_run_row)\n",
        "      cleaned_recovery_run_row['PlayOutcome'] = original_play_copy['PlayOutcome']\n",
        "      list_recovery_runs.append(cleaned_recovery_run_row)\n",
        "\n",
        "\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "vTkvC31rhw7V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, play in df_2023_sack_week1['PlayDescription'].items():\n",
        "  if play.find(\"FUMBLES\") != -1:\n",
        "    # print(play)\n",
        "    extract_fumble_data_sack(df_2023_sack_week1, play, idx)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "B5SxgBLuAx8l",
        "outputId": "c6966023-7771-4f0e-e712-bae8f9f080b1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"str\") to list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e2fdec6fbfc3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FUMBLES\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# print(play)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mextract_fumble_data_sack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2023_sack_week1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e75a35d74467>\u001b[0m in \u001b[0;36mextract_fumble_data_sack\u001b[0;34m(df_plays, play, play_index)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# which should be the intended play. (additional data includes: injuries, penalties, elibility, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0mplay_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\". \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mplay_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\". \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I need to figure out how I am going to extract forced fumble data\n",
        "# - I need to be mindful of multiple fumbles in a single play\n",
        "#   - This would mean multiple players forcing fumbles?\n",
        "#   - This would mean multiple yardage after recoveries\n",
        "\n",
        "# I also need to be aware that if multiple fumbles were to occur in a single play,\n",
        "# I would like to effectively keep track of who caused a fumble when. So from the\n",
        "# initial play that was fumbled, I would like to record who caused that fumble in that\n",
        "# row. Then on the recovery for yardage, if it is fumbled, I would like to record who\n",
        "# caused that fumble in that row. And so on.\n",
        "\n",
        "# Initial play row will contain all data\n",
        "# - Added rows will be to represent yardage after recovery\n",
        "\n",
        "def extract_fumble_data_sack(df_plays, play, play_index):\n",
        "\n",
        "  # 'PlayDescription' is made up of a group of sentences, each containing individual actions of the play.\n",
        "  play_elements = play.split(\". \")\n",
        "  extracted_fumble_details = [None] * len(play_elements)\n",
        "  back_to_main_cleaning_method = []\n",
        "\n",
        "  # list for plays that need multiple rows\n",
        "  multi_row_play = []\n",
        "\n",
        "  # To collect distinct actions that will become their own rows\n",
        "  df_fumble_recovery = []\n",
        "\n",
        "  for i in play_elements:\n",
        "    # Assuming everything is going back to main cleaning method\n",
        "    back_to_main_cleaning_method.append(i)\n",
        "\n",
        "    # Fumble sentences to (fumble details)\n",
        "    if i.find('FUMBLES') != -1:\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      extracted_fumble_details.pop(play_elements.index(i))\n",
        "      extracted_fumble_details.insert(play_elements.index(i), i)\n",
        "\n",
        "    # Yardage after recovery\n",
        "    fumble_recovery_action = re.findall(run_after_recovery, i)\n",
        "    if len(fumble_recovery_action) > 0:\n",
        "      back_to_main_cleaning_method.pop(back_to_main_cleaning_method.index(i))\n",
        "      recovery_for_yardage_row = df_plays.iloc[play_index].copy()\n",
        "      recovery_for_yardage_row['PlayDescription'] = i\n",
        "      recovery_for_yardage_row['PlayOutcome'] = 'Run'\n",
        "      recovery_for_yardage_row = pd.DataFrame([recovery_for_yardage_row], columns=df_plays.columns)\n",
        "      cleaned_recovery_for_yardage_row = clean_run_plays(recovery_for_yardage_row)\n",
        "      df_fumble_recovery.append(cleaned_recovery_for_yardage_row)\n",
        "\n",
        "  if len(df_fumble_recovery) > 0:\n",
        "    main_play_row = df_plays.iloc[play_index].copy()\n",
        "    main_play_row['PlayDescription'] = \". \".join(back_to_main_cleaning_method)\n",
        "    main_play_row = pd.DataFrame([main_play_row], columns=df_plays.columns)\n",
        "    cleaned_main_play_row = clean_sacked_plays(main_play_row)\n",
        "\n",
        "    multi_row_play.append(main_play_row)\n",
        "    multi_row_play.extend(df_fumble_recovery)\n",
        "\n",
        "    df_split_single_play = pd.DataFrame(columns=df_plays.columns)\n",
        "\n",
        "    for i in multi_row_play:\n",
        "      if len(extracted_fumble_details) > 0:\n",
        "        row_index = i.index[0]\n",
        "        i.at[row_index, 'FumbleDetails'] = extracted_fumble_details\n",
        "\n",
        "      if df_split_single_play.empty:\n",
        "        df_split_single_play = i\n",
        "      else:\n",
        "        df_split_single_play = pd.concat([df_split_single_play, i], ignore_index=True)\n",
        "\n",
        "    return None, None, df_split_single_play\n",
        "\n",
        "  return extracted_fumble_details, back_to_main_cleaning_method, pd.DataFrame()"
      ],
      "metadata": {
        "id": "xpM7Y11-ZtZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SACKS\n"
      ],
      "metadata": {
        "id": "Rp-Bszm-B9rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fumble occurs\n",
        "# - Should I create a new method?\n",
        "# - Would an existing method work?\n",
        "# Split into 2 separate rows\n",
        "# 1. will contain sack + who caused the fumble\n",
        "# 2. recovery yardage after sack\n",
        "\n",
        "def clean_sacked_plays(df_plays, index_start = None):\n",
        "\n",
        "  # Will cut df_plays starting from index_start (narrowing our search space)\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_sacked_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Sack')]\n",
        "  else:\n",
        "    df_sacked_plays = df_plays[df_plays['PlayOutcome'].str.contains('Sack')]\n",
        "\n",
        "  for idx, play in df_sacked_plays['PlayDescription'].items():\n",
        "\n",
        "    ################\n",
        "    # Play details #\n",
        "    ################\n",
        "\n",
        "    # TimeOnTheClock\n",
        "    TimeOnTheClock = re.findall(time_on_clock_pattern, play)\n",
        "    if len(TimeOnTheClock) > 0:\n",
        "      df_plays.loc[idx, 'TimeOnTheClock'] = TimeOnTheClock[0]\n",
        "\n",
        "    ###########\n",
        "    # FUMBLES #\n",
        "    ###########\n",
        "\n",
        "    if play.find('FUMBLES') != -1:\n",
        "      fumble_details, play, df_added_rows = extract_fumble_data_sack(df_plays, play, idx)\n",
        "      if not df_added_rows.empty:\n",
        "        df_before = df_plays.iloc[:idx]\n",
        "        df_after = df_plays.iloc[idx+1:]\n",
        "        df_plays = pd.concat([df_before, df_added_rows, df_after], ignore_index=True)\n",
        "        index_of_last_added_row = idx + len(df_added_rows) - 1\n",
        "        return clean_sacked_plays(df_plays, index_of_last_added_row)\n",
        "\n",
        "      df_plays.at[idx, 'FumbleDetails'] = fumble_details\n",
        "      play = \". \".join(play)\n",
        "\n",
        "\n",
        "    #############\n",
        "    #  OFFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Formation\n",
        "    Formation = re.findall(formation, play)\n",
        "    if len(Formation) > 0:\n",
        "      if Formation[0] == 'Aborted':\n",
        "        pass\n",
        "      else:\n",
        "        df_plays.loc[idx, 'Formation'] = Formation[0]\n",
        "\n",
        "    # Sacked Passer\n",
        "    sacked_passer_name = re.findall(sacked_passer_name_pattern, play)\n",
        "    if len(sacked_passer_name) > 0:\n",
        "      df_plays.loc[idx, 'Passer'] = sacked_passer_name[0]\n",
        "\n",
        "    # Yardage lost\n",
        "    yardage = re.findall(yardage_from_sack, play)\n",
        "    if len(yardage) > 0:\n",
        "      df_plays.loc[idx, 'Yardage'] = int(yardage[0])\n",
        "\n",
        "    #############\n",
        "    #  DEFENSE  #\n",
        "    #############\n",
        "\n",
        "    # Solo sack (One person sacked the passer)\n",
        "    solo_sack = re.findall(defense_tackler_1_name_pattern, play)\n",
        "    if len(solo_sack) > 0:\n",
        "      df_plays.loc[idx, 'SackedBy'] = solo_sack[0]\n",
        "\n",
        "    # Split sack (A sack was given to the passer by multiple defenders)\n",
        "    split_sack = re.findall(split_sack_pattern, play)\n",
        "    if len(split_sack) > 0:\n",
        "      df_plays.at[idx, 'SackedBy'] = list(split_sack[0])\n",
        "\n",
        "    ##############\n",
        "    #  INJURIES  #\n",
        "    ##############\n",
        "\n",
        "    injuries = re.findall(injury, play)\n",
        "    if len(injuries) > 0:\n",
        "      df_plays.at[idx, 'InjuredPlayers'] = injuries\n",
        "\n",
        "    #############\n",
        "    #  PENALTY  #\n",
        "    #############\n",
        "\n",
        "    # Accepted Penalty\n",
        "    if play.find('PENALTY') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('PENALTY') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'AcceptedPenalty'] = penalties\n",
        "\n",
        "    # Declined Penalty\n",
        "    if play.find('Penalty') != -1:\n",
        "      play_elements = play.split(\". \")\n",
        "      penalties = []\n",
        "      for i in play_elements:\n",
        "        if i.find('Penalty') != -1:\n",
        "          penalties.append(i)\n",
        "      df_plays.at[idx, 'DeclinedPenalty'] = penalties\n",
        "\n",
        "    if df_sacked_plays.tail(1).index.tolist()[0] == idx:\n",
        "      return df_plays\n",
        "\n",
        "  # return df_plays"
      ],
      "metadata": {
        "id": "s8F6nfFsCG6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TOUCHDOWN PLAYS"
      ],
      "metadata": {
        "id": "5B4OEwz2AwnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_touchdown_plays(df_plays, index_start=None):\n",
        "\n",
        "  # Cut 'df_plays' to begin from 'index_start' to the last touchdown play available in dataframe\n",
        "  if index_start != None:\n",
        "    df_plays_adjusted = df_plays.iloc[df_plays.index.tolist().index(index_start):]\n",
        "    df_touchdown_plays = df_plays_adjusted[df_plays_adjusted['PlayOutcome'].str.contains('Touchdown')]\n",
        "  else:\n",
        "    df_touchdown_plays = df_plays[df_plays['PlayOutcome'].str.contains('Touchdown')]\n",
        "\n",
        "  # Iterating through every touchdown play within 'df_touchdown_plays'\n",
        "  for idx, play in df_touchdown_plays['PlayDescription'].items():\n",
        "\n",
        "    # - Once i figure out what kind of touchdown it was, then I will be able to\n",
        "    #   determine the 'PlayType'\n",
        "\n",
        "    # Still need to clean intercepted play types\n",
        "    if play.find(\"INTERCEPTED\") != -1:\n",
        "\n",
        "      # creating a copy of the incercepted touchdown play and cleaning the copy\n",
        "      intercepted_touchdown_row = df_plays.iloc[idx].copy()\n",
        "      intercepted_touchdown_row['PlayOutcome'] = 'Interception'\n",
        "      intercepted_touchdown_row['IsScoringPlay'] = 0 # This will only be the value for the team that threw the interception\n",
        "      intercepted_touchdown_row = pd.DataFrame([intercepted_touchdown_row], columns=df_plays.columns)\n",
        "      intercepted_touchdown_row.reset_index(drop=True, inplace=True)\n",
        "      cleaned_intercepted_touchdown_row = clean_intercepted_plays(intercepted_touchdown_row)\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:idx]\n",
        "      df_after_row = df_plays.iloc[idx+1:]\n",
        "      df_plays = pd.concat([df_before_row, cleaned_intercepted_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+len(cleaned_intercepted_touchdown_row))\n",
        "\n",
        "      continue\n",
        "\n",
        "    ######################\n",
        "    # PASSING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    # If a play has a passer throwing the ball, I am assuming it is a passing play\n",
        "    passing_play = re.findall(passer_name_pattern, play)\n",
        "    if len(passing_play) > 0:\n",
        "\n",
        "      # creating a copy of the passing touchdown play row and cleaning the copy\n",
        "      passing_touchdown_row = df_plays.iloc[idx].copy()\n",
        "      passing_touchdown_row['PlayType'] = 'Pass'\n",
        "      passing_touchdown_row['PlayOutcome'] = 'Pass'\n",
        "      passing_touchdown_row['IsScoringPlay'] = 1\n",
        "      passing_touchdown_row = pd.DataFrame([passing_touchdown_row], columns=df_plays.columns)\n",
        "      cleaned_passing_touchdown_row = clean_pass_plays(passing_touchdown_row)\n",
        "      cleaned_passing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].iloc[idx]\n",
        "\n",
        "      # Replacing old row with cleaned row\n",
        "      df_before_row = df_plays.iloc[:idx]\n",
        "      df_after_row = df_plays.iloc[idx+1:]\n",
        "      df_plays = pd.concat([df_before_row, cleaned_passing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "      # Recursion to update 'df_plays'\n",
        "      if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "        return df_plays\n",
        "      else:\n",
        "        return clean_touchdown_plays(df_plays, idx+1)\n",
        "\n",
        "\n",
        "    ######################\n",
        "    # RUSHING TOUCHDOWNS #\n",
        "    ######################\n",
        "\n",
        "    # Rusher\n",
        "    rusher_patterns = [rusher_pattern, run_after_recovery]\n",
        "    # Loop through patterns and find the first match\n",
        "    for pattern in rusher_patterns:\n",
        "      rusher = re.findall(pattern, play)\n",
        "      if len(rusher) > 0:\n",
        "        # creating a copy of the rushing touchdown play row and cleaning the copy\n",
        "        rushing_touchdown_row = df_plays.iloc[idx].copy()\n",
        "        rushing_touchdown_row['PlayType'] = 'Run'\n",
        "        rushing_touchdown_row['PlayOutcome'] = 'Run'\n",
        "        rushing_touchdown_row['IsScoringPlay'] = 1\n",
        "        rushing_touchdown_row = pd.DataFrame([rushing_touchdown_row], columns=df_plays.columns)\n",
        "        cleaned_rushing_touchdown_row = clean_run_plays(rushing_touchdown_row)\n",
        "        cleaned_rushing_touchdown_row['PlayOutcome'] = df_plays['PlayOutcome'].iloc[idx]\n",
        "\n",
        "        # Replacing old row with cleaned row\n",
        "        df_before_row = df_plays.iloc[:idx]\n",
        "        df_after_row = df_plays.iloc[idx+1:]\n",
        "        df_plays = pd.concat([df_before_row, cleaned_rushing_touchdown_row, df_after_row], ignore_index=True)\n",
        "\n",
        "        # Recursion to update 'df_plays'\n",
        "        if df_touchdown_plays.tail(1).index.tolist()[0] == idx:\n",
        "          return df_plays\n",
        "        else:\n",
        "          return clean_touchdown_plays(df_plays, idx+1)"
      ],
      "metadata": {
        "id": "GjW0FNUyOSVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PIPELINE MAIN METHOD"
      ],
      "metadata": {
        "id": "i0nkzhWl5FEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PURPOSE:\n",
        "# - Accept a dataframe of plays (dataframes formatted by NFL_Scrapers) and\n",
        "#   return a cleaned dataframe of those plays.\n",
        "# INPUT PARAMTERS:\n",
        "# df_all_plays         - dataframe - all plays in raw form from NFL_Scraper that user\n",
        "#                                    would like to clean.\n",
        "# OUTPUT:\n",
        "# df_all_plays_cleaned - dataframe - all plays from 'df_all_plays' cleaned and data\n",
        "#                                    dispersed into individual new features.\n",
        "\n",
        "# CURRENT DESIGN PLAN:\n",
        "# 1. Use uniquely designed methods for each play type to clean within dataframe\n",
        "#    - (e.g. pass, run, touchdown, punt, sack, ... )\n",
        "# 2. Repeat until all plays within dataframe have been cleaned.\n",
        "#   NOTE:\n",
        "#   - It is important to fully clean a play type before moving to the next\n",
        "#      because sometimes cleaning could involve adding a new row to the dataframe,\n",
        "#      causing a reset to the dataframes indexing.\n",
        "#      - If we were to separate all play types from the beginning, the indexes\n",
        "#        could shift around causing, for example, an index that might originally\n",
        "#        point to a run play to now instead point at a pass play.\n",
        "\n",
        "# NOTES:\n",
        "# - I think \"PlayOutcomes\" is what determines the yardage gained on an intended play?\n",
        "#   - This does not seem right to me.\n",
        "#   - EXAMPLE:\n",
        "#     - (9:54) Bre.Hall left end to BUF 22 for -1 yards (G.Rousseau)\n",
        "#       FUMBLES (G.Rousseau), ball out of bounds at BUF 25.\n",
        "#       - I would think that Bre.Hall would get docked -1 yards for his run.\n",
        "#         - But I believe that he is actually docked -4\n",
        "#           - 'PlayStart' = 2nd & 9 at BUF 21\n",
        "#           - The play ends at BUF 25\n",
        "#             - In my opinion and how I am going to track yardage is based on\n",
        "#               possession of the ball. So I will track this as -1 yard not -4.\n",
        "\n",
        "def clean_dataframe_of_plays(df_all_plays):\n",
        "\n",
        "  ###########################\n",
        "  # NEW COLUMN DESCRIPTIONS #\n",
        "  ###########################\n",
        "\n",
        "  # PlayType           - The type of play (e.g. pass/run)\n",
        "  # TimeOnTheClock     - The time that was on the clock when the play started\n",
        "  # Formation          - Play formation\n",
        "  # Passer             - Player that threw the ball (mostly the quarterback)\n",
        "  # Rusher             - Player that ran the ball (mostly the runningback)\n",
        "  # Receiver           - Player on the same team as the passer that caught the ball\n",
        "  # PassType           - Whether the pass was a deep or short pass?\n",
        "  # Direction          - Where the ball is going during the play\n",
        "  # Yardage            - Yards gained during the play\n",
        "  # TackleBy1          - Main tackler on the play (could be solo or could be with someone else)\n",
        "  # TackleBy2          - Assisted tackler1\n",
        "  # PressureBy         - Defender that applied pressure to the passer\n",
        "  # InterceptedBy      - Defender that intercepted the passing play\n",
        "  # FumbleDetails      - A list that has what happened after the fumble\n",
        "  #                      - [forced fumble by, recovered by, yards gained, tackled by]\n",
        "  # ReverseDetails     - A list having plays leading up to play reversal\n",
        "  # InjuredPlayers     - Players that were injured during the play\n",
        "  # PenaltyDescription - If there is a penalty, gives a description of it\n",
        "  #                      - [who caused the penalty, what was the penalty, yards lost if penalty accepted]\n",
        "\n",
        "  new_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"PassType\", \"Direction\", \"Yardage\",\n",
        "                \"TackleBy1\", \"TackleBy2\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\",\n",
        "                \"FumbleDetails\", \"ReverseDetails\",\n",
        "                \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\"]\n",
        "\n",
        "  string_columns = [\"PlayType\", \"TimeOnTheClock\", \"Formation\", \"Passer\", \"Rusher\", \"Receiver\", \"PassType\", \"Direction\",\n",
        "                    \"TackleBy1\", \"TackleBy2\", \"PressureBy\", \"InterceptedBy\", \"SackedBy\",\n",
        "                    \"FumbleDetails\", \"ReverseDetails\",\n",
        "                    \"InjuredPlayers\", \"AcceptedPenalty\", \"DeclinedPenalty\"]\n",
        "\n",
        "  int_columns = [\"Yardage\"]\n",
        "\n",
        "  ########################################\n",
        "  # RETURN DATAFRAME WITH ADDED FEATURES #\n",
        "  ########################################\n",
        "\n",
        "  df_all_plays_cleaned = df_all_plays.copy()\n",
        "  df_all_plays_cleaned = df_all_plays_cleaned.reindex(columns=df_all_plays_cleaned.columns.tolist() + new_columns)\n",
        "  df_all_plays_cleaned[string_columns] = df_all_plays_cleaned[string_columns].astype(str)\n",
        "  df_all_plays_cleaned[int_columns] = df_all_plays_cleaned[int_columns].astype(float)\n",
        "\n",
        "  ########################################\n",
        "  # GETTING PLAY CATEGORIES AND CLEANING #\n",
        "  ########################################\n",
        "\n",
        "  df_all_plays_cleaned = clean_run_plays(df_all_plays_cleaned)\n",
        "  df_all_plays_cleaned = clean_pass_plays(df_all_plays_cleaned)\n",
        "  df_all_plays_cleaned = clean_intercepted_plays(df_all_plays_cleaned)\n",
        "  df_all_plays_cleaned = clean_touchdown_plays(df_all_plays_cleaned)\n",
        "  df_all_plays_cleaned = clean_sacked_plays(df_all_plays_cleaned)\n",
        "\n",
        "  return df_all_plays_cleaned"
      ],
      "metadata": {
        "id": "7cbY2K4pyH8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING AREA"
      ],
      "metadata": {
        "id": "FN4kSTEvpiHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "week1_2023_plays_copy = week1_2023_plays.copy()\n",
        "\n",
        "df_week1_plays_cleaned = clean_dataframe_of_plays(week1_2023_plays_copy)"
      ],
      "metadata": {
        "id": "nnsfvTSwZy2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_week1_plays_cleaned.shape"
      ],
      "metadata": {
        "id": "l79N87_MWkzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All touchdown plays that still need to be cleaned\n",
        "\n",
        "df_touchdown_plays = df_week1_plays_cleaned.loc[df_week1_plays_cleaned['PlayOutcome'].str.contains('Touchdown')]\n",
        "\n",
        "for idx, play in df_touchdown_plays['PlayDescription'].items():\n",
        "  if play.find(\"INTERCEPTED\") != -1:\n",
        "    continue\n",
        "  passing_td = re.findall(passer_name_pattern, play)\n",
        "  if len(passing_td) > 0:\n",
        "    continue\n",
        "  rushing_td = re.findall(rusher_pattern, play)\n",
        "  if len(rushing_td) > 0:\n",
        "    continue\n",
        "  time = re.findall(time_on_clock_pattern, play)\n",
        "  if len(time) == 0:\n",
        "    continue\n",
        "  print(idx)\n",
        "  print(play)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Pbr9FagoEUtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sacked_plays = df_week1_plays_cleaned.loc[df_week1_plays_cleaned['PlayOutcome'].str.contains('Sack')]\n",
        "\n",
        "for idx, play in df_sacked_plays['PlayDescription'].items():\n",
        "  if play.find('FUMBLES') != -1:\n",
        "    print(idx)\n",
        "    print(play)\n",
        "    print()"
      ],
      "metadata": {
        "id": "3eyaI6J0NWsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_run_plays = df_week1_plays_cleaned.loc[df_week1_plays_cleaned['PlayOutcome'].str.contains('Run')]\n",
        "\n",
        "for idx, play in df_run_plays['PlayDescription'].items():\n",
        "  if play.find('FUMBLES') != -1:\n",
        "    print(idx)\n",
        "    print(play)\n",
        "    print()"
      ],
      "metadata": {
        "id": "Lb35wMVSG0Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, play in df_week1_plays_cleaned['PlayDescription'].items():\n",
        "  # if play.find('FUMBLES') != -1:\n",
        "  if df_week1_plays_cleaned['FumbleDetails'].iloc[idx] != 'nan':\n",
        "    print(idx)\n",
        "    print(play)\n",
        "    # print(df_week1_plays_cleaned['FumbleDetails'].iloc[idx])\n",
        "    print()"
      ],
      "metadata": {
        "id": "Ieb2TwKwDVa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_week1_plays_cleaned.iloc[15]\n",
        "df_week1_plays_cleaned.iloc[358]"
      ],
      "metadata": {
        "id": "Gn363g0xpdHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cleaned dataset observations"
      ],
      "metadata": {
        "id": "TrudwcGMsfXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Home and Away teams (Week 1, 2023)"
      ],
      "metadata": {
        "id": "lXOsRYYuiXxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Season 2023 Week 1 schedule\n",
        "\n",
        "df_2023_week1_schedule = df_week1_plays_cleaned[['HomeTeam', 'AwayTeam', 'Season', 'Date', 'Day']].drop_duplicates().sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "df_2023_week1_schedule"
      ],
      "metadata": {
        "id": "B6IG2fOYiKXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Offense Stats"
      ],
      "metadata": {
        "id": "Kty3o5BakJHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing Example\n",
        "1. Top 10 players who threw the ball the most\n",
        "2. All passing plays from a specified player\n",
        "3. Total passing yards from the specified player\n",
        "4. All receivers who caught a pass from specified player\n",
        "5. Top target receiver from specified player\n",
        "6. Top target receiver catching yards"
      ],
      "metadata": {
        "id": "x7HEPQQfljJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Top 10 players who threw the ball the most\n",
        "\n",
        "passers = df_week1_plays_cleaned['Passer'].loc[(df_week1_plays_cleaned['Season'] == 2023) &\n",
        "                                                (df_week1_plays_cleaned['Week'] == 'Week 1')].value_counts().head(10)\n",
        "\n",
        "passers"
      ],
      "metadata": {
        "id": "KvRVh6l1otcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. All passing plays from a specified player\n",
        "\n",
        "passer = 'C.Stroud'\n",
        "\n",
        "df_passing_plays_by = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['Passer'] == passer)].sort_index()\n",
        "\n",
        "df_passing_plays_by"
      ],
      "metadata": {
        "id": "0DGuCScd9F4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Total passing yards from the specified player\n",
        "\n",
        "total_passing_yards = df_passing_plays_by['Yardage'].sum()\n",
        "\n",
        "total_passing_yards"
      ],
      "metadata": {
        "id": "-wm5b50j4FMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. All receivers who caught a pass from specified player\n",
        "\n",
        "df_all_passing_targets = df_passing_plays_by['Receiver'].loc[(df_passing_plays_by['Receiver'] != 'nan')].value_counts()\n",
        "\n",
        "df_all_passing_targets"
      ],
      "metadata": {
        "id": "-OUKU50FmpF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Top target receiver from specified player\n",
        "\n",
        "df_passers_top_target_plays = df_passing_plays_by.loc[df_passing_plays_by['Receiver'] == df_all_passing_targets.head(1).index.tolist()[0]]\n",
        "\n",
        "df_passers_top_target_plays"
      ],
      "metadata": {
        "id": "kXdWMGFvoiQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Top target receiver catching yards\n",
        "\n",
        "df_passers_top_target_plays['Yardage'].sum()"
      ],
      "metadata": {
        "id": "Kd8KnBkS626T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rushing Example\n",
        "1. All players who carried the ball from a specified team\n",
        "2. All rushing plays from top rusher of a specified team\n",
        "3. Total rushing yards from top rusher of a specified team\n"
      ],
      "metadata": {
        "id": "97KoHskt7L1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. All players who carried the ball from a specified team\n",
        "# - I need to map team names to their abbreviations in the future\n",
        "#   - For right now 'Cowboys' == 'DAL'\n",
        "\n",
        "team_abbreviation = 'DAL'\n",
        "\n",
        "team_rushers = df_week1_plays_cleaned['Rusher'].loc[(df_week1_plays_cleaned['TeamWithPossession'] == team_abbreviation) &\n",
        "                                                    (df_week1_plays_cleaned['Rusher'] != 'nan')].value_counts()\n",
        "\n",
        "team_rushers"
      ],
      "metadata": {
        "id": "69FfTCMXixy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. All rushing plays from top rusher of a specified team\n",
        "\n",
        "df_top_rushers_plays = df_week1_plays_cleaned.loc[df_week1_plays_cleaned['Rusher'] == team_rushers.head(1).index.tolist()[0]]\n",
        "\n",
        "df_top_rushers_plays"
      ],
      "metadata": {
        "id": "Mxz_46XlgJBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Total rushing yards from top rusher of a specified team\n",
        "\n",
        "df_top_rushers_plays['Yardage'].sum()"
      ],
      "metadata": {
        "id": "b3IVGfdmghVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defense Stats"
      ],
      "metadata": {
        "id": "rnZ_khFBkMkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. All defensive plays from a specified team\n",
        "2. All solo tackles made form the specified team\n",
        "3. All plays of the player with the most solo tackles"
      ],
      "metadata": {
        "id": "0qVzjmwn0h5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. All defensive plays from a specified team\n",
        "\n",
        "team_name = 'Jets'\n",
        "team_abbreviation = 'NYJ'\n",
        "\n",
        "df_all_game_plays = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['HomeTeam'] == team_name) |\n",
        "                                                (df_week1_plays_cleaned['AwayTeam'] == team_name)]\n",
        "\n",
        "df_all_defensive_plays = df_all_game_plays.loc[df_all_game_plays['TeamWithPossession'] != team_abbreviation]\n",
        "\n",
        "df_all_defensive_plays"
      ],
      "metadata": {
        "id": "6Fe03HcKj5sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. All solo tackles made form the specified team\n",
        "\n",
        "df_all_solo_tackles = df_all_defensive_plays['TackleBy1'].loc[(df_all_defensive_plays['TackleBy1'] != 'nan') &\n",
        "                                                              (df_all_defensive_plays['TackleBy2'] == 'nan')].value_counts()\n",
        "\n",
        "df_all_solo_tackles"
      ],
      "metadata": {
        "id": "OO51dwHrk3lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. All plays of the player with the most solo tackles\n",
        "\n",
        "df_player_with_most_tackles = df_week1_plays_cleaned.loc[(df_week1_plays_cleaned['TackleBy1'] == df_all_solo_tackles.head(1).index.tolist()[0]) &\n",
        "                                                         (df_week1_plays_cleaned['TackleBy2'] == 'nan')]\n",
        "\n",
        "df_player_with_most_tackles"
      ],
      "metadata": {
        "id": "BQKjFEDxleGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}